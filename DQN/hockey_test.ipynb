{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73a80ed1-4855-4c3e-a082-115f24d01f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import laserhockey.hockey_env as h_env\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from dqn_agent import DQNAgent\n",
    "from evaluate_func import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fa33afe-7032-46c5-b3d4-b045c88fbe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "# Define hyperparameters\n",
    "gamma = 1\n",
    "eps_min = 0.\n",
    "eps_max = 0.\n",
    "eps_decay = 0.95\n",
    "target_update_freq = 20\n",
    "learning_rate = 1e-3\n",
    "num_evaluation_episodes = 200\n",
    "max_steps_per_episode = 500\n",
    "batch_size = 32\n",
    "use_target = True\n",
    "use_dueling = True\n",
    "use_clipping = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3ae3637-9821-4c11-be90-aa835bfdd63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = h_env.HockeyEnv(mode=0, verbose=False)\n",
    "opponent = h_env.BasicOpponent(weak=True)\n",
    "ac_space = env.discrete_action_space\n",
    "o_space = env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50fe7d33-06a1-4f52-8be3-59b049fe55e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_agent = DQNAgent(o_space, ac_space, discount=gamma, eps=eps_max, eps_end=eps_min, \n",
    "                   eps_decay=eps_decay, use_target_net=use_target, update_target_every= target_update_freq, \n",
    "                   dueling=use_dueling, cliping=use_clipping)\n",
    "q_agent.load_agent(\"saved_models/\", step=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8e2afcf-4c06-4166-bf15-d349a0292b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation stats:\n",
      "Won: 37, Lost: 86\n",
      "Winrate: 0.18\n",
      "Average reward: -9.96\n",
      "Average episode length: 171.22\n"
     ]
    }
   ],
   "source": [
    "won_games = 0\n",
    "lost_games = 0\n",
    "drawn_games = 0\n",
    "ep_rewards = []\n",
    "ep_length = []\n",
    "ep_touched_puck = []\n",
    "\n",
    "\n",
    "for episode_counter in range(num_evaluation_episodes):\n",
    "    episode_reward = 0\n",
    "    episode_length = 0\n",
    "    obs, _ = env.reset()\n",
    "    obs_opp = env.obs_agent_two()\n",
    "\n",
    "    agent_touched_puck = False\n",
    "    puck_starts_in_our_half = True if env.puck.position[0] < 5 else False\n",
    "\n",
    "    for step in range(env.max_timesteps + 1):\n",
    "            if env.player1_has_puck and puck_starts_in_our_half: \n",
    "                agent_touched_puck = True\n",
    "\n",
    "            discr_agent_move = q_agent.act(obs)\n",
    "            agent_move = env.discrete_to_continous_action(discr_agent_move)\n",
    "            opponent_move = opponent.act(obs_opp)\n",
    "\n",
    "            (obs_next, reward, done, _, _) = env.step(np.hstack((agent_move, opponent_move)))\n",
    "\n",
    "            obs = obs_next\n",
    "            obs_opp = env.obs_agent_two()\n",
    "            episode_reward += reward\n",
    "            episode_length += 1\n",
    "\n",
    "            if done:\n",
    "                ep_rewards.append(episode_reward)\n",
    "                ep_length.append(episode_length)\n",
    "                ep_touched_puck.append(agent_touched_puck)\n",
    "                episode_length = 0\n",
    "                if env.winner == 1:\n",
    "                    won_games += 1\n",
    "                elif env.winner == -1:\n",
    "                    lost_games += 1\n",
    "                else:\n",
    "                    drawn_games += 1\n",
    "                break                \n",
    "\n",
    "\n",
    "print(\"Evaluation stats:\")\n",
    "print(f'Won: {won_games}, Lost: {lost_games}')\n",
    "print(f'Winrate: {np.round(won_games / num_evaluation_episodes, 2)}')\n",
    "print(f'Average reward: {np.round(np.mean(ep_rewards), 2)}')\n",
    "print(f'Average episode length: {np.round(np.mean(ep_length), 2)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
